{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fca8ea9-66a9-4f84-a259-c012ed629850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "                         AGRISHIELD RISK PREDICTION MODEL TRAINING\n",
      "                            ML Pipeline - 2026\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# AGRISHIELD RISK PREDICTION MODEL TRAINING\n",
    "# ============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix, roc_auc_score\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\" \"*25 + \"AGRISHIELD RISK PREDICTION MODEL TRAINING\")\n",
    "print(\" \"*28 + \"ML Pipeline - 2026\")\n",
    "print(\"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b12e0120-cbf0-42c1-97ab-3108a34766d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• STEP 1: LOADING PROCESSED DATA\n",
      "--------------------------------------------------------------------------------\n",
      "‚úÖ Dataset loaded: (15113, 27)\n",
      "   Years: 1997 - 2019\n",
      "   Crops: 55\n",
      "   States: 24\n",
      "   Districts: 24\n",
      "\n",
      "üìä Sample Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crop</th>\n",
       "      <th>State</th>\n",
       "      <th>Year</th>\n",
       "      <th>Season</th>\n",
       "      <th>Yield</th>\n",
       "      <th>Crop_Failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arecanut</td>\n",
       "      <td>Assam</td>\n",
       "      <td>1997</td>\n",
       "      <td>Whole Year</td>\n",
       "      <td>0.796087</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arhar/Tur</td>\n",
       "      <td>Assam</td>\n",
       "      <td>1997</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>0.710435</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Castor Seed</td>\n",
       "      <td>Assam</td>\n",
       "      <td>1997</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>0.238333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coconut</td>\n",
       "      <td>Assam</td>\n",
       "      <td>1997</td>\n",
       "      <td>Whole Year</td>\n",
       "      <td>5238.051739</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cotton(Lint)</td>\n",
       "      <td>Assam</td>\n",
       "      <td>1997</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>0.420909</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Crop  State  Year      Season        Yield  Crop_Failure\n",
       "0      Arecanut  Assam  1997  Whole Year     0.796087             1\n",
       "1     Arhar/Tur  Assam  1997      Kharif     0.710435             0\n",
       "2   Castor Seed  Assam  1997      Kharif     0.238333             1\n",
       "3       Coconut  Assam  1997  Whole Year  5238.051739             1\n",
       "4  Cotton(Lint)  Assam  1997      Kharif     0.420909             1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 1: LOAD PROCESSED DATA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"üì• STEP 1: LOADING PROCESSED DATA\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv('../data/processed/merged_dataset.csv')\n",
    "    print(f\"‚úÖ Dataset loaded: {df.shape}\")\n",
    "    print(f\"   Years: {int(df['Year'].min())} - {int(df['Year'].max())}\")\n",
    "    print(f\"   Crops: {df['Crop'].nunique()}\")\n",
    "    print(f\"   States: {df['State'].nunique()}\")\n",
    "    print(f\"   Districts: {df['District'].nunique()}\")\n",
    "    \n",
    "    # Display first few rows\n",
    "    print(\"\\nüìä Sample Data:\")\n",
    "    display(df[['Crop', 'State', 'Year', 'Season', 'Yield', 'Crop_Failure']].head())\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå ERROR: merged_dataset.csv not found!\")\n",
    "    print(\"   Please run data_preprocessing.ipynb first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0eafe6b5-062f-4ff1-ba5c-ea561d66381c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚öôÔ∏è  STEP 2: PREPARING FEATURES\n",
      "--------------------------------------------------------------------------------\n",
      "Encoding categorical variables...\n",
      "‚úÖ Encoded 55 crops\n",
      "‚úÖ Encoded 24 states\n",
      "\n",
      "‚úÖ Features prepared:\n",
      "   Feature count: 11\n",
      "   Sample size: 15,113\n",
      "   Features: ['Crop_Encoded', 'State_Encoded', 'Season_Encoded', 'Avg_Temperature', 'Total_Rainfall', 'Avg_Humidity', 'Soil_Quality_Score', 'Rainfall_Deviation', 'Temperature_Deviation', 'Disaster_Occurred', 'Severity_Score']\n",
      "\n",
      "üìä Target distribution:\n",
      "   Failures: 3,310 (21.90%)\n",
      "   Success: 11,803 (78.10%)\n",
      "\n",
      "üìä Feature Statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crop_Encoded</th>\n",
       "      <th>State_Encoded</th>\n",
       "      <th>Season_Encoded</th>\n",
       "      <th>Avg_Temperature</th>\n",
       "      <th>Total_Rainfall</th>\n",
       "      <th>Avg_Humidity</th>\n",
       "      <th>Soil_Quality_Score</th>\n",
       "      <th>Rainfall_Deviation</th>\n",
       "      <th>Temperature_Deviation</th>\n",
       "      <th>Disaster_Occurred</th>\n",
       "      <th>Severity_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15113.000000</td>\n",
       "      <td>15113.000000</td>\n",
       "      <td>15113.000000</td>\n",
       "      <td>15113.000000</td>\n",
       "      <td>15113.000000</td>\n",
       "      <td>15113.000000</td>\n",
       "      <td>15113.000000</td>\n",
       "      <td>1.511300e+04</td>\n",
       "      <td>15113.0</td>\n",
       "      <td>15113.000000</td>\n",
       "      <td>15113.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29.229736</td>\n",
       "      <td>11.347317</td>\n",
       "      <td>2.039105</td>\n",
       "      <td>25.741150</td>\n",
       "      <td>945.333762</td>\n",
       "      <td>71.379078</td>\n",
       "      <td>0.724067</td>\n",
       "      <td>-4.513236e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.156951</td>\n",
       "      <td>0.364918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16.062429</td>\n",
       "      <td>7.239475</td>\n",
       "      <td>1.147819</td>\n",
       "      <td>4.162029</td>\n",
       "      <td>867.819498</td>\n",
       "      <td>6.237021</td>\n",
       "      <td>0.066468</td>\n",
       "      <td>5.243676e-15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363767</td>\n",
       "      <td>0.879990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>14.738462</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>-1.718258e-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>161.957143</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>882.670423</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>44.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>1211.420000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>3682.842857</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>1.583372e-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Crop_Encoded  State_Encoded  Season_Encoded  Avg_Temperature  \\\n",
       "count  15113.000000   15113.000000    15113.000000     15113.000000   \n",
       "mean      29.229736      11.347317        2.039105        25.741150   \n",
       "std       16.062429       7.239475        1.147819         4.162029   \n",
       "min        0.000000       0.000000        1.000000        20.000000   \n",
       "25%       16.000000       6.000000        1.000000        20.000000   \n",
       "50%       29.000000      11.000000        2.000000        27.000000   \n",
       "75%       44.000000      17.000000        3.000000        28.000000   \n",
       "max       54.000000      23.000000        4.000000        35.000000   \n",
       "\n",
       "       Total_Rainfall  Avg_Humidity  Soil_Quality_Score  Rainfall_Deviation  \\\n",
       "count    15113.000000  15113.000000        15113.000000        1.511300e+04   \n",
       "mean       945.333762     71.379078            0.724067       -4.513236e-16   \n",
       "std        867.819498      6.237021            0.066468        5.243676e-15   \n",
       "min         14.738462     60.000000            0.610000       -1.718258e-14   \n",
       "25%        161.957143     65.000000            0.660000        0.000000e+00   \n",
       "50%        882.670423     70.000000            0.720000        0.000000e+00   \n",
       "75%       1211.420000     78.000000            0.790000        0.000000e+00   \n",
       "max       3682.842857     78.000000            0.830000        1.583372e-14   \n",
       "\n",
       "       Temperature_Deviation  Disaster_Occurred  Severity_Score  \n",
       "count                15113.0       15113.000000    15113.000000  \n",
       "mean                     0.0           0.156951        0.364918  \n",
       "std                      0.0           0.363767        0.879990  \n",
       "min                      0.0           0.000000        0.000000  \n",
       "25%                      0.0           0.000000        0.000000  \n",
       "50%                      0.0           0.000000        0.000000  \n",
       "75%                      0.0           0.000000        0.000000  \n",
       "max                      0.0           1.000000        3.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 2: PREPARE FEATURES FOR ML\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n‚öôÔ∏è  STEP 2: PREPARING FEATURES\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Encode categorical variables\n",
    "print(\"Encoding categorical variables...\")\n",
    "\n",
    "# Crop encoder\n",
    "crop_encoder = LabelEncoder()\n",
    "df['Crop_Encoded'] = crop_encoder.fit_transform(df['Crop'])\n",
    "\n",
    "# State encoder\n",
    "state_encoder = LabelEncoder()\n",
    "df['State_Encoded'] = state_encoder.fit_transform(df['State'])\n",
    "\n",
    "print(f\"‚úÖ Encoded {df['Crop'].nunique()} crops\")\n",
    "print(f\"‚úÖ Encoded {df['State'].nunique()} states\")\n",
    "\n",
    "# Select features (only those a farmer can easily provide)\n",
    "feature_cols = [\n",
    "    'Crop_Encoded',\n",
    "    'State_Encoded',\n",
    "    'Season_Encoded',\n",
    "    'Avg_Temperature',\n",
    "    'Total_Rainfall',\n",
    "    'Avg_Humidity',\n",
    "    'Soil_Quality_Score',\n",
    "    'Rainfall_Deviation',\n",
    "    'Temperature_Deviation',\n",
    "    'Disaster_Occurred',\n",
    "    'Severity_Score'\n",
    "]\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df['Crop_Failure']\n",
    "\n",
    "print(f\"\\n‚úÖ Features prepared:\")\n",
    "print(f\"   Feature count: {len(feature_cols)}\")\n",
    "print(f\"   Sample size: {len(X):,}\")\n",
    "print(f\"   Features: {feature_cols}\")\n",
    "print(f\"\\nüìä Target distribution:\")\n",
    "print(f\"   Failures: {y.sum():,} ({y.mean()*100:.2f}%)\")\n",
    "print(f\"   Success: {(y==0).sum():,} ({(1-y.mean())*100:.2f}%)\")\n",
    "\n",
    "# Display feature statistics\n",
    "print(\"\\nüìä Feature Statistics:\")\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dde2e549-9f4d-4e7b-b914-1bba0d67c07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ STEP 3: SAVING ENCODERS AND LISTS\n",
      "--------------------------------------------------------------------------------\n",
      "‚úÖ Saved: crop_encoder.pkl\n",
      "‚úÖ Saved: state_encoder.pkl\n",
      "‚úÖ Saved: crop_list.pkl (55 crops)\n",
      "‚úÖ Saved: state_list.pkl (24 states)\n",
      "‚úÖ Saved: district_list.pkl (24 districts)\n",
      "\n",
      "üìã Available Crops (first 20):\n",
      "['Arecanut', 'Arhar/Tur', 'Bajra', 'Banana', 'Barley', 'Black Pepper', 'Cardamom', 'Cashewnut', 'Castor Seed', 'Coconut', 'Coriander', 'Cotton(Lint)', 'Cowpea(Lobia)', 'Dry Chillies', 'Garlic', 'Ginger', 'Gram', 'Groundnut', 'Guar Seed', 'Horse-Gram']\n",
      "\n",
      "üìã Available States:\n",
      "['Andhra Pradesh', 'Arunachal Pradesh', 'Assam', 'Bihar', 'Delhi', 'Goa', 'Gujarat', 'Haryana', 'Jammu And Kashmir', 'Jharkhand', 'Karnataka', 'Kerala', 'Madhya Pradesh', 'Maharashtra', 'Manipur', 'Meghalaya', 'Mizoram', 'Nagaland', 'Punjab', 'Sikkim', 'Tamil Nadu', 'Tripura', 'Uttar Pradesh', 'West Bengal']\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 3: SAVE ENCODERS AND LISTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüíæ STEP 3: SAVING ENCODERS AND LISTS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Create models directory\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "# Save encoders\n",
    "with open('../models/crop_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(crop_encoder, f)\n",
    "print(\"‚úÖ Saved: crop_encoder.pkl\")\n",
    "\n",
    "with open('../models/state_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(state_encoder, f)\n",
    "print(\"‚úÖ Saved: state_encoder.pkl\")\n",
    "\n",
    "# Save lists for frontend dropdowns\n",
    "crop_list = sorted(df['Crop'].unique().tolist())\n",
    "state_list = sorted(df['State'].unique().tolist())\n",
    "district_list = sorted(df['District'].unique().tolist())\n",
    "\n",
    "with open('../models/crop_list.pkl', 'wb') as f:\n",
    "    pickle.dump(crop_list, f)\n",
    "print(f\"‚úÖ Saved: crop_list.pkl ({len(crop_list)} crops)\")\n",
    "\n",
    "with open('../models/state_list.pkl', 'wb') as f:\n",
    "    pickle.dump(state_list, f)\n",
    "print(f\"‚úÖ Saved: state_list.pkl ({len(state_list)} states)\")\n",
    "\n",
    "with open('../models/district_list.pkl', 'wb') as f:\n",
    "    pickle.dump(district_list, f)\n",
    "print(f\"‚úÖ Saved: district_list.pkl ({len(district_list)} districts)\")\n",
    "\n",
    "print(f\"\\nüìã Available Crops (first 20):\")\n",
    "print(crop_list[:20])\n",
    "\n",
    "print(f\"\\nüìã Available States:\")\n",
    "print(state_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2194889-8d81-4699-8ec3-5d08a276dc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä STEP 4: SPLITTING DATA\n",
      "--------------------------------------------------------------------------------\n",
      "‚úÖ Split complete:\n",
      "   Training samples: 12,090\n",
      "   Testing samples: 3,023\n",
      "\n",
      "   Training failures: 2,648 (21.90%)\n",
      "   Testing failures: 662 (21.90%)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 4: TRAIN-TEST SPLIT\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüìä STEP 4: SPLITTING DATA\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Split data (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Split complete:\")\n",
    "print(f\"   Training samples: {len(X_train):,}\")\n",
    "print(f\"   Testing samples: {len(X_test):,}\")\n",
    "print(f\"\\n   Training failures: {y_train.sum():,} ({y_train.mean()*100:.2f}%)\")\n",
    "print(f\"   Testing failures: {y_test.sum():,} ({y_test.mean()*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b783f3ce-cef7-4aaf-87fb-360d313dc109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìè STEP 5: SCALING FEATURES\n",
      "--------------------------------------------------------------------------------\n",
      "‚úÖ Features scaled using StandardScaler\n",
      "‚úÖ Scaler saved: scaler.pkl\n",
      "\n",
      "üìä Scaled feature ranges (first 5 features):\n",
      "   Crop_Encoded                  : [-1.81, 1.54]\n",
      "   State_Encoded                 : [-1.57, 1.61]\n",
      "   Season_Encoded                : [-0.91, 1.71]\n",
      "   Avg_Temperature               : [-1.38, 2.22]\n",
      "   Total_Rainfall                : [-1.07, 3.15]\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 5: FEATURE SCALING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüìè STEP 5: SCALING FEATURES\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Initialize scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training data and transform both\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Save scaler\n",
    "with open('../models/scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "print(\"‚úÖ Features scaled using StandardScaler\")\n",
    "print(\"‚úÖ Scaler saved: scaler.pkl\")\n",
    "\n",
    "print(\"\\nüìä Scaled feature ranges (first 5 features):\")\n",
    "for i, col in enumerate(feature_cols[:5]):\n",
    "    print(f\"   {col:30s}: [{X_train_scaled[:, i].min():.2f}, {X_train_scaled[:, i].max():.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d8b454a-345b-4a77-b9d9-16a366e9e5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ STEP 6: TRAINING ML MODELS\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Training: Logistic Regression\n",
      "================================================================================\n",
      "Training model...\n",
      "‚úÖ Training complete!\n",
      "\n",
      "üìä PERFORMANCE METRICS:\n",
      "   Train Accuracy: 0.5660\n",
      "   Test Accuracy:  0.5607\n",
      "   Precision:      0.2729\n",
      "   Recall:         0.6042\n",
      "   F1-Score:       0.3759\n",
      "   AUC-ROC:        0.6116\n",
      "\n",
      "üìâ CONFUSION MATRIX:\n",
      "                Predicted\n",
      "                No  Yes\n",
      "   Actual No  [ 1295  1066]\n",
      "   Actual Yes [  262   400]\n",
      "\n",
      "   True Negatives:  1,295\n",
      "   False Positives: 1,066\n",
      "   False Negatives: 262\n",
      "   True Positives:  400\n",
      "\n",
      "================================================================================\n",
      "Training: Random Forest\n",
      "================================================================================\n",
      "Training model...\n",
      "‚úÖ Training complete!\n",
      "\n",
      "üìä PERFORMANCE METRICS:\n",
      "   Train Accuracy: 0.8577\n",
      "   Test Accuracy:  0.8207\n",
      "   Precision:      0.5638\n",
      "   Recall:         0.8006\n",
      "   F1-Score:       0.6617\n",
      "   AUC-ROC:        0.8882\n",
      "\n",
      "üìâ CONFUSION MATRIX:\n",
      "                Predicted\n",
      "                No  Yes\n",
      "   Actual No  [ 1951   410]\n",
      "   Actual Yes [  132   530]\n",
      "\n",
      "   True Negatives:  1,951\n",
      "   False Positives: 410\n",
      "   False Negatives: 132\n",
      "   True Positives:  530\n",
      "\n",
      "================================================================================\n",
      "Training: Gradient Boosting\n",
      "================================================================================\n",
      "Training model...\n",
      "‚úÖ Training complete!\n",
      "\n",
      "üìä PERFORMANCE METRICS:\n",
      "   Train Accuracy: 0.8884\n",
      "   Test Accuracy:  0.8664\n",
      "   Precision:      0.7710\n",
      "   Recall:         0.5544\n",
      "   F1-Score:       0.6450\n",
      "   AUC-ROC:        0.9002\n",
      "\n",
      "üìâ CONFUSION MATRIX:\n",
      "                Predicted\n",
      "                No  Yes\n",
      "   Actual No  [ 2252   109]\n",
      "   Actual Yes [  295   367]\n",
      "\n",
      "   True Negatives:  2,252\n",
      "   False Positives: 109\n",
      "   False Negatives: 295\n",
      "   True Positives:  367\n",
      "\n",
      "================================================================================\n",
      "‚úÖ All models trained successfully!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 6: TRAIN MULTIPLE MODELS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nü§ñ STEP 6: TRAINING ML MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(\n",
    "        random_state=42,\n",
    "        max_iter=1000,\n",
    "        class_weight='balanced'\n",
    "    ),\n",
    "    'Random Forest': RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        random_state=42,\n",
    "        max_depth=15,\n",
    "        min_samples_split=5,\n",
    "        class_weight='balanced',\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(\n",
    "        n_estimators=100,\n",
    "        random_state=42,\n",
    "        max_depth=7,\n",
    "        learning_rate=0.1\n",
    "    )\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Training: {name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Train\n",
    "    print(\"Training model...\")\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    print(\"‚úÖ Training complete!\")\n",
    "    \n",
    "    # Predict\n",
    "    y_pred_train = model.predict(X_train_scaled)\n",
    "    y_pred_test = model.predict(X_test_scaled)\n",
    "    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_acc = accuracy_score(y_train, y_pred_train)\n",
    "    test_acc = accuracy_score(y_test, y_pred_test)\n",
    "    precision = precision_score(y_test, y_pred_test, zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred_test, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred_test, zero_division=0)\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'train_accuracy': train_acc,\n",
    "        'test_accuracy': test_acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'auc': auc\n",
    "    }\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"\\nüìä PERFORMANCE METRICS:\")\n",
    "    print(f\"   Train Accuracy: {train_acc:.4f}\")\n",
    "    print(f\"   Test Accuracy:  {test_acc:.4f}\")\n",
    "    print(f\"   Precision:      {precision:.4f}\")\n",
    "    print(f\"   Recall:         {recall:.4f}\")\n",
    "    print(f\"   F1-Score:       {f1:.4f}\")\n",
    "    print(f\"   AUC-ROC:        {auc:.4f}\")\n",
    "    \n",
    "    # Confusion matrix\n",
    "    print(f\"\\nüìâ CONFUSION MATRIX:\")\n",
    "    cm = confusion_matrix(y_test, y_pred_test)\n",
    "    print(f\"                Predicted\")\n",
    "    print(f\"                No  Yes\")\n",
    "    print(f\"   Actual No  [{cm[0][0]:5d} {cm[0][1]:5d}]\")\n",
    "    print(f\"   Actual Yes [{cm[1][0]:5d} {cm[1][1]:5d}]\")\n",
    "    print(f\"\\n   True Negatives:  {cm[0][0]:,}\")\n",
    "    print(f\"   False Positives: {cm[0][1]:,}\")\n",
    "    print(f\"   False Negatives: {cm[1][0]:,}\")\n",
    "    print(f\"   True Positives:  {cm[1][1]:,}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ All models trained successfully!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed435914-5bf6-40d4-b2c8-f4a9d9d9ea10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä STEP 7: MODEL COMPARISON\n",
      "================================================================================\n",
      "\n",
      "üèÜ MODEL COMPARISON TABLE:\n",
      "              Model  Train Acc  Test Acc  Precision   Recall  F1-Score  AUC-ROC\n",
      "Logistic Regression   0.566005  0.560701   0.272851 0.604230  0.375940 0.611646\n",
      "      Random Forest   0.857651  0.820708   0.563830 0.800604  0.661673 0.888160\n",
      "  Gradient Boosting   0.888420  0.866358   0.771008 0.554381  0.644991 0.900237\n",
      "\n",
      "ü•á BEST MODELS BY METRIC:\n",
      "   Test Acc    : Gradient Boosting         (0.8664)\n",
      "   Precision   : Gradient Boosting         (0.7710)\n",
      "   Recall      : Random Forest             (0.8006)\n",
      "   F1-Score    : Random Forest             (0.6617)\n",
      "   AUC-ROC     : Gradient Boosting         (0.9002)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Acc</th>\n",
       "      <th>Test Acc</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC-ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.566005</td>\n",
       "      <td>0.560701</td>\n",
       "      <td>0.272851</td>\n",
       "      <td>0.604230</td>\n",
       "      <td>0.375940</td>\n",
       "      <td>0.611646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.857651</td>\n",
       "      <td>0.820708</td>\n",
       "      <td>0.563830</td>\n",
       "      <td>0.800604</td>\n",
       "      <td>0.661673</td>\n",
       "      <td>0.888160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.888420</td>\n",
       "      <td>0.866358</td>\n",
       "      <td>0.771008</td>\n",
       "      <td>0.554381</td>\n",
       "      <td>0.644991</td>\n",
       "      <td>0.900237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Train Acc  Test Acc  Precision    Recall  F1-Score  \\\n",
       "0  Logistic Regression   0.566005  0.560701   0.272851  0.604230  0.375940   \n",
       "1        Random Forest   0.857651  0.820708   0.563830  0.800604  0.661673   \n",
       "2    Gradient Boosting   0.888420  0.866358   0.771008  0.554381  0.644991   \n",
       "\n",
       "    AUC-ROC  \n",
       "0  0.611646  \n",
       "1  0.888160  \n",
       "2  0.900237  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 7: COMPARE MODELS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüìä STEP 7: MODEL COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create comparison dataframe\n",
    "comparison = pd.DataFrame({\n",
    "    'Model': list(results.keys()),\n",
    "    'Train Acc': [results[m]['train_accuracy'] for m in results],\n",
    "    'Test Acc': [results[m]['test_accuracy'] for m in results],\n",
    "    'Precision': [results[m]['precision'] for m in results],\n",
    "    'Recall': [results[m]['recall'] for m in results],\n",
    "    'F1-Score': [results[m]['f1_score'] for m in results],\n",
    "    'AUC-ROC': [results[m]['auc'] for m in results]\n",
    "})\n",
    "\n",
    "print(\"\\nüèÜ MODEL COMPARISON TABLE:\")\n",
    "print(comparison.to_string(index=False))\n",
    "\n",
    "# Highlight best model for each metric\n",
    "print(\"\\nü•á BEST MODELS BY METRIC:\")\n",
    "for metric in ['Test Acc', 'Precision', 'Recall', 'F1-Score', 'AUC-ROC']:\n",
    "    best_model = comparison.loc[comparison[metric].idxmax(), 'Model']\n",
    "    best_score = comparison[metric].max()\n",
    "    print(f\"   {metric:12s}: {best_model:25s} ({best_score:.4f})\")\n",
    "\n",
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6523e017-1b34-4c6d-b0a7-25b678131a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÜ STEP 8: SELECTING BEST MODEL\n",
      "================================================================================\n",
      "\n",
      "‚úÖ BEST MODEL: Random Forest\n",
      "\n",
      "üìä FINAL PERFORMANCE:\n",
      "   Test Accuracy: 0.8207\n",
      "   Precision:     0.5638\n",
      "   Recall:        0.8006\n",
      "   F1-Score:      0.6617\n",
      "   AUC-ROC:       0.8882\n",
      "\n",
      "üíæ Model saved: ../models/crop_failure_model.pkl\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 8: SELECT BEST MODEL\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüèÜ STEP 8: SELECTING BEST MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Select based on F1-score (balanced metric for imbalanced data)\n",
    "best_model_name = max(results, key=lambda x: results[x]['f1_score'])\n",
    "best_model = results[best_model_name]['model']\n",
    "best_metrics = results[best_model_name]\n",
    "\n",
    "print(f\"\\n‚úÖ BEST MODEL: {best_model_name}\")\n",
    "print(f\"\\nüìä FINAL PERFORMANCE:\")\n",
    "print(f\"   Test Accuracy: {best_metrics['test_accuracy']:.4f}\")\n",
    "print(f\"   Precision:     {best_metrics['precision']:.4f}\")\n",
    "print(f\"   Recall:        {best_metrics['recall']:.4f}\")\n",
    "print(f\"   F1-Score:      {best_metrics['f1_score']:.4f}\")\n",
    "print(f\"   AUC-ROC:       {best_metrics['auc']:.4f}\")\n",
    "\n",
    "# Save best model\n",
    "model_path = '../models/crop_failure_model.pkl'\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "print(f\"\\nüíæ Model saved: {model_path}\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7cdb5acf-59c0-4e17-9bc0-0e361903a5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä STEP 9: FEATURE IMPORTANCE\n",
      "================================================================================\n",
      "\n",
      "üîç TOP 10 MOST IMPORTANT FEATURES:\n",
      "   Crop_Encoded                  : 0.6137 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   State_Encoded                 : 0.1278 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   Total_Rainfall                : 0.0978 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   Soil_Quality_Score            : 0.0686 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   Rainfall_Deviation            : 0.0216 ‚ñà‚ñà\n",
      "   Avg_Humidity                  : 0.0171 ‚ñà\n",
      "   Severity_Score                : 0.0167 ‚ñà\n",
      "   Avg_Temperature               : 0.0146 ‚ñà\n",
      "   Season_Encoded                : 0.0125 ‚ñà\n",
      "   Disaster_Occurred             : 0.0096 \n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 9: FEATURE IMPORTANCE\n",
    "# ============================================================================\n",
    "\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    print(\"\\nüìä STEP 9: FEATURE IMPORTANCE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    importances = best_model.feature_importances_\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': feature_cols,\n",
    "        'Importance': importances\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nüîç TOP 10 MOST IMPORTANT FEATURES:\")\n",
    "    for i, row in feature_importance.head(10).iterrows():\n",
    "        print(f\"   {row['Feature']:30s}: {row['Importance']:.4f} {'‚ñà' * int(row['Importance']*100)}\")\n",
    "    \n",
    "    feature_importance\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Selected model doesn't have feature importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "122a5a55-1b88-41c8-9cf8-bb58a2733562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                              ‚úÖ TRAINING COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "üìÅ FILES CREATED IN ../models/:\n",
      "   ‚îú‚îÄ‚îÄ crop_failure_model.pkl      (Best ML model)\n",
      "   ‚îú‚îÄ‚îÄ scaler.pkl                  (Feature scaler)\n",
      "   ‚îú‚îÄ‚îÄ crop_encoder.pkl            (Crop label encoder)\n",
      "   ‚îú‚îÄ‚îÄ state_encoder.pkl           (State label encoder)\n",
      "   ‚îú‚îÄ‚îÄ crop_list.pkl               (List of crops)\n",
      "   ‚îú‚îÄ‚îÄ state_list.pkl              (List of states)\n",
      "   ‚îú‚îÄ‚îÄ district_list.pkl           (List of districts)\n",
      "   ‚îî‚îÄ‚îÄ district_info.pkl           (District soil info)\n",
      "\n",
      "üéØ BEST MODEL: Random Forest\n",
      "   F1-Score: 0.6617\n",
      "   Accuracy: 0.8207\n",
      "\n",
      "üìä DATASET INFO:\n",
      "   Total samples: 15,113\n",
      "   Training samples: 12,090\n",
      "   Testing samples: 3,023\n",
      "   Number of crops: 55\n",
      "   Number of states: 24\n",
      "\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Model is ready for deployment!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 10: FINAL SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" \"*30 + \"‚úÖ TRAINING COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüìÅ FILES CREATED IN ../models/:\")\n",
    "print(f\"   ‚îú‚îÄ‚îÄ crop_failure_model.pkl      (Best ML model)\")\n",
    "print(f\"   ‚îú‚îÄ‚îÄ scaler.pkl                  (Feature scaler)\")\n",
    "print(f\"   ‚îú‚îÄ‚îÄ crop_encoder.pkl            (Crop label encoder)\")\n",
    "print(f\"   ‚îú‚îÄ‚îÄ state_encoder.pkl           (State label encoder)\")\n",
    "print(f\"   ‚îú‚îÄ‚îÄ crop_list.pkl               (List of crops)\")\n",
    "print(f\"   ‚îú‚îÄ‚îÄ state_list.pkl              (List of states)\")\n",
    "print(f\"   ‚îú‚îÄ‚îÄ district_list.pkl           (List of districts)\")\n",
    "print(f\"   ‚îî‚îÄ‚îÄ district_info.pkl           (District soil info)\")\n",
    "\n",
    "print(f\"\\nüéØ BEST MODEL: {best_model_name}\")\n",
    "print(f\"   F1-Score: {best_metrics['f1_score']:.4f}\")\n",
    "print(f\"   Accuracy: {best_metrics['test_accuracy']:.4f}\")\n",
    "\n",
    "print(f\"\\nüìä DATASET INFO:\")\n",
    "print(f\"   Total samples: {len(df):,}\")\n",
    "print(f\"   Training samples: {len(X_train):,}\")\n",
    "print(f\"   Testing samples: {len(X_test):,}\")\n",
    "print(f\"   Number of crops: {df['Crop'].nunique()}\")\n",
    "print(f\"   Number of states: {df['State'].nunique()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "print(\"‚úÖ Model is ready for deployment!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a517bfe3-4ada-4251-82e0-9de48f533d89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
