{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "616c228c-8818-42a5-bcf0-8198811c3fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                         AGRISHIELD DATA PREPROCESSING\n",
      "                            Real Datasets - 2025\n",
      "================================================================================\n",
      "\n",
      "üì• STEP 1: LOADING RAW DATASETS\n",
      "--------------------------------------------------------------------------------\n",
      "‚úÖ Crop Data: (19689, 10)\n",
      "   Columns: ['Crop', 'Crop_Year', 'Season', 'State', 'Area', 'Production', 'Annual_Rainfall', 'Fertilizer', 'Pesticide', 'Yield']\n",
      "‚úÖ Weather Data: (641, 19)\n",
      "   Columns: ['STATE_UT_NAME', 'DISTRICT', 'JAN', 'FEB', 'MAR', 'APR', 'MAY', 'JUN', 'JUL', 'AUG', 'SEP', 'OCT', 'NOV', 'DEC', 'ANNUAL', 'Jan-Feb', 'Mar-May', 'Jun-Sep', 'Oct-Dec']\n",
      "‚úÖ Disaster Data: (16126, 45)\n",
      "   Columns: ['Year', 'Seq', 'Glide', 'Disaster Group', 'Disaster Subgroup', 'Disaster Type', 'Disaster Subtype', 'Disaster Subsubtype', 'Event Name', 'Country', 'ISO', 'Region', 'Continent', 'Location', 'Origin', 'Associated Dis', 'Associated Dis2', 'OFDA Response', 'Appeal', 'Declaration', 'Aid Contribution', 'Dis Mag Value', 'Dis Mag Scale', 'Latitude', 'Longitude', 'Local Time', 'River Basin', 'Start Year', 'Start Month', 'Start Day', 'End Year', 'End Month', 'End Day', 'Total Deaths', 'No Injured', 'No Affected', 'No Homeless', 'Total Affected', \"Insured Damages ('000 US$)\", \"Total Damages ('000 US$)\", 'CPI', 'Adm Level', 'Admin1 Code', 'Admin2 Code', 'Geo Locations']\n",
      "‚úÖ Soil Data: (2200, 8)\n",
      "   Columns: ['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall', 'label']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" \"*25 + \"AGRISHIELD DATA PREPROCESSING\")\n",
    "print(\" \"*28 + \"Real Datasets - 2025\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: LOAD RAW DATASETS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"üì• STEP 1: LOADING RAW DATASETS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# 1. CROP PRODUCTION DATA\n",
    "try:\n",
    "    crop_df = pd.read_csv('../data/raw/crop_production.csv')\n",
    "    print(f\"‚úÖ Crop Data: {crop_df.shape}\")\n",
    "    print(f\"   Columns: {list(crop_df.columns)}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading crop data: {e}\")\n",
    "    exit()\n",
    "\n",
    "# 2. WEATHER DATA (Rainfall)\n",
    "try:\n",
    "    weather_df = pd.read_csv('../data/raw/weather_data.csv')\n",
    "    print(f\"‚úÖ Weather Data: {weather_df.shape}\")\n",
    "    print(f\"   Columns: {list(weather_df.columns)}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading weather data: {e}\")\n",
    "    exit()\n",
    "\n",
    "# 3. DISASTER DATA\n",
    "try:\n",
    "    disaster_df = pd.read_csv('../data/raw/disaster_data.csv')\n",
    "    print(f\"‚úÖ Disaster Data: {disaster_df.shape}\")\n",
    "    print(f\"   Columns: {list(disaster_df.columns)}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading disaster data: {e}\")\n",
    "    exit()\n",
    "\n",
    "# 4. SOIL DATA\n",
    "try:\n",
    "    soil_df = pd.read_csv('../data/raw/soil_data.csv')\n",
    "    print(f\"‚úÖ Soil Data: {soil_df.shape}\")\n",
    "    print(f\"   Columns: {list(soil_df.columns)}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading soil data: {e}\")\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f88b286-a052-418d-a804-e5f3588b5b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üßπ STEP 2: CLEANING CROP PRODUCTION DATA\n",
      "--------------------------------------------------------------------------------\n",
      "Original shape: (19689, 10)\n",
      "‚úÖ Cleaned shape: (19437, 11)\n",
      "   Years: 1997 - 2020\n",
      "   Crops: 55\n",
      "   States: 30\n",
      "\n",
      "üìä Top 10 Crops:\n",
      "Crop\n",
      "Rice                 1191\n",
      "Maize                 969\n",
      "Moong(Green Gram)     730\n",
      "Urad                  726\n",
      "Groundnut             721\n",
      "Sesamum               680\n",
      "Potato                623\n",
      "Sugarcane             601\n",
      "Wheat                 540\n",
      "Rapeseed &Mustard     525\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üìä Seasons:\n",
      "Season\n",
      "Kharif        8125\n",
      "Rabi          5695\n",
      "Whole Year    3629\n",
      "Summer        1187\n",
      "Autumn         413\n",
      "Winter         388\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crop</th>\n",
       "      <th>Year</th>\n",
       "      <th>Season</th>\n",
       "      <th>State</th>\n",
       "      <th>Area</th>\n",
       "      <th>Production</th>\n",
       "      <th>Annual_Rainfall</th>\n",
       "      <th>Fertilizer</th>\n",
       "      <th>Pesticide</th>\n",
       "      <th>Yield</th>\n",
       "      <th>District</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arecanut</td>\n",
       "      <td>1997</td>\n",
       "      <td>Whole Year</td>\n",
       "      <td>Assam</td>\n",
       "      <td>73814.0</td>\n",
       "      <td>56708</td>\n",
       "      <td>2051.4</td>\n",
       "      <td>7024878.38</td>\n",
       "      <td>22882.34</td>\n",
       "      <td>0.796087</td>\n",
       "      <td>Assam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arhar/Tur</td>\n",
       "      <td>1997</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>Assam</td>\n",
       "      <td>6637.0</td>\n",
       "      <td>4685</td>\n",
       "      <td>2051.4</td>\n",
       "      <td>631643.29</td>\n",
       "      <td>2057.47</td>\n",
       "      <td>0.710435</td>\n",
       "      <td>Assam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Castor Seed</td>\n",
       "      <td>1997</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>Assam</td>\n",
       "      <td>796.0</td>\n",
       "      <td>22</td>\n",
       "      <td>2051.4</td>\n",
       "      <td>75755.32</td>\n",
       "      <td>246.76</td>\n",
       "      <td>0.238333</td>\n",
       "      <td>Assam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coconut</td>\n",
       "      <td>1997</td>\n",
       "      <td>Whole Year</td>\n",
       "      <td>Assam</td>\n",
       "      <td>19656.0</td>\n",
       "      <td>126905000</td>\n",
       "      <td>2051.4</td>\n",
       "      <td>1870661.52</td>\n",
       "      <td>6093.36</td>\n",
       "      <td>5238.051739</td>\n",
       "      <td>Assam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cotton(Lint)</td>\n",
       "      <td>1997</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>Assam</td>\n",
       "      <td>1739.0</td>\n",
       "      <td>794</td>\n",
       "      <td>2051.4</td>\n",
       "      <td>165500.63</td>\n",
       "      <td>539.09</td>\n",
       "      <td>0.420909</td>\n",
       "      <td>Assam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Crop  Year      Season  State     Area  Production  \\\n",
       "0      Arecanut  1997  Whole Year  Assam  73814.0       56708   \n",
       "1     Arhar/Tur  1997      Kharif  Assam   6637.0        4685   \n",
       "2   Castor Seed  1997      Kharif  Assam    796.0          22   \n",
       "3       Coconut  1997  Whole Year  Assam  19656.0   126905000   \n",
       "4  Cotton(Lint)  1997      Kharif  Assam   1739.0         794   \n",
       "\n",
       "   Annual_Rainfall  Fertilizer  Pesticide        Yield District  \n",
       "0           2051.4  7024878.38   22882.34     0.796087    Assam  \n",
       "1           2051.4   631643.29    2057.47     0.710435    Assam  \n",
       "2           2051.4    75755.32     246.76     0.238333    Assam  \n",
       "3           2051.4  1870661.52    6093.36  5238.051739    Assam  \n",
       "4           2051.4   165500.63     539.09     0.420909    Assam  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 2: CLEAN CROP PRODUCTION DATA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüßπ STEP 2: CLEANING CROP PRODUCTION DATA\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Rename columns to standard format\n",
    "crop_df.columns = crop_df.columns.str.strip()\n",
    "crop_df.rename(columns={\n",
    "    'Crop_Year': 'Year',\n",
    "    'State': 'State',\n",
    "    'Crop': 'Crop',\n",
    "    'Season': 'Season',\n",
    "    'Area': 'Area',\n",
    "    'Production': 'Production',\n",
    "    'Yield': 'Yield'\n",
    "}, inplace=True)\n",
    "\n",
    "print(f\"Original shape: {crop_df.shape}\")\n",
    "\n",
    "# Remove missing values\n",
    "crop_df = crop_df.dropna(subset=['State', 'Crop', 'Season', 'Year'])\n",
    "\n",
    "# Convert to numeric\n",
    "crop_df['Production'] = pd.to_numeric(crop_df['Production'], errors='coerce').fillna(0)\n",
    "crop_df['Area'] = pd.to_numeric(crop_df['Area'], errors='coerce').fillna(0)\n",
    "crop_df['Year'] = pd.to_numeric(crop_df['Year'], errors='coerce')\n",
    "crop_df['Yield'] = pd.to_numeric(crop_df['Yield'], errors='coerce')\n",
    "\n",
    "# Remove zero/negative yields\n",
    "crop_df = crop_df[crop_df['Yield'] > 0]\n",
    "\n",
    "# Remove outliers (top 0.5%)\n",
    "crop_df = crop_df[crop_df['Yield'] < crop_df.groupby('Crop')['Yield'].transform(lambda x: x.quantile(0.995))]\n",
    "\n",
    "# Standardize text fields\n",
    "crop_df['State'] = crop_df['State'].str.strip().str.title()\n",
    "crop_df['Crop'] = crop_df['Crop'].str.strip().str.title()\n",
    "crop_df['Season'] = crop_df['Season'].str.strip().str.title()\n",
    "\n",
    "# Add District column (since original doesn't have it, we'll use State as district for now)\n",
    "crop_df['District'] = crop_df['State']\n",
    "\n",
    "print(f\"‚úÖ Cleaned shape: {crop_df.shape}\")\n",
    "print(f\"   Years: {int(crop_df['Year'].min())} - {int(crop_df['Year'].max())}\")\n",
    "print(f\"   Crops: {crop_df['Crop'].nunique()}\")\n",
    "print(f\"   States: {crop_df['State'].nunique()}\")\n",
    "\n",
    "print(\"\\nüìä Top 10 Crops:\")\n",
    "print(crop_df['Crop'].value_counts().head(10))\n",
    "\n",
    "print(\"\\nüìä Seasons:\")\n",
    "print(crop_df['Season'].value_counts())\n",
    "\n",
    "crop_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9545b1b-d596-4696-bac8-b4affb389954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚òÅÔ∏è  STEP 3: PROCESSING WEATHER DATA\n",
      "--------------------------------------------------------------------------------\n",
      "Weather data shape: (641, 23)\n",
      "States in weather data: 35\n",
      "‚úÖ Weather records created: 140\n",
      "   States covered: 35\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Season</th>\n",
       "      <th>Total_Rainfall</th>\n",
       "      <th>Avg_Temperature</th>\n",
       "      <th>Avg_Humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Andaman And Nicobar Islands</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>1917.366667</td>\n",
       "      <td>28</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andaman And Nicobar Islands</td>\n",
       "      <td>Rabi</td>\n",
       "      <td>548.233333</td>\n",
       "      <td>20</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Andaman And Nicobar Islands</td>\n",
       "      <td>Summer</td>\n",
       "      <td>864.466667</td>\n",
       "      <td>35</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andaman And Nicobar Islands</td>\n",
       "      <td>Whole Year</td>\n",
       "      <td>2911.400000</td>\n",
       "      <td>27</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>1960.806250</td>\n",
       "      <td>28</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>Rabi</td>\n",
       "      <td>391.143750</td>\n",
       "      <td>20</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>Summer</td>\n",
       "      <td>1066.806250</td>\n",
       "      <td>35</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>Whole Year</td>\n",
       "      <td>2927.375000</td>\n",
       "      <td>27</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Assam</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>1777.648148</td>\n",
       "      <td>28</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Assam</td>\n",
       "      <td>Rabi</td>\n",
       "      <td>161.574074</td>\n",
       "      <td>20</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         State      Season  Total_Rainfall  Avg_Temperature  \\\n",
       "0  Andaman And Nicobar Islands      Kharif     1917.366667               28   \n",
       "1  Andaman And Nicobar Islands        Rabi      548.233333               20   \n",
       "2  Andaman And Nicobar Islands      Summer      864.466667               35   \n",
       "3  Andaman And Nicobar Islands  Whole Year     2911.400000               27   \n",
       "4            Arunachal Pradesh      Kharif     1960.806250               28   \n",
       "5            Arunachal Pradesh        Rabi      391.143750               20   \n",
       "6            Arunachal Pradesh      Summer     1066.806250               35   \n",
       "7            Arunachal Pradesh  Whole Year     2927.375000               27   \n",
       "8                        Assam      Kharif     1777.648148               28   \n",
       "9                        Assam        Rabi      161.574074               20   \n",
       "\n",
       "   Avg_Humidity  \n",
       "0            78  \n",
       "1            65  \n",
       "2            60  \n",
       "3            70  \n",
       "4            78  \n",
       "5            65  \n",
       "6            60  \n",
       "7            70  \n",
       "8            78  \n",
       "9            65  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 3: PROCESS WEATHER DATA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n‚òÅÔ∏è  STEP 3: PROCESSING WEATHER DATA\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Clean column names\n",
    "weather_df.columns = weather_df.columns.str.strip()\n",
    "\n",
    "# Rename columns\n",
    "weather_df.rename(columns={\n",
    "    'STATE_UT_NAME': 'State',\n",
    "    'DISTRICT': 'District'\n",
    "}, inplace=True)\n",
    "\n",
    "print(f\"Weather data shape: {weather_df.shape}\")\n",
    "print(f\"States in weather data: {weather_df['State'].nunique()}\")\n",
    "\n",
    "# Calculate seasonal rainfall\n",
    "weather_df['Kharif_Rainfall'] = weather_df[['JUN', 'JUL', 'AUG', 'SEP', 'OCT']].sum(axis=1)\n",
    "weather_df['Rabi_Rainfall'] = weather_df[['NOV', 'DEC', 'JAN', 'FEB', 'MAR']].sum(axis=1)\n",
    "weather_df['Summer_Rainfall'] = weather_df[['APR', 'MAY', 'JUN']].sum(axis=1)\n",
    "weather_df['Annual_Rainfall'] = weather_df['ANNUAL']\n",
    "\n",
    "# Standardize state names\n",
    "weather_df['State'] = weather_df['State'].str.strip().str.title()\n",
    "\n",
    "# Create a mapping of state to average rainfall by season\n",
    "weather_mapping = []\n",
    "\n",
    "for state in weather_df['State'].unique():\n",
    "    state_data = weather_df[weather_df['State'] == state]\n",
    "    \n",
    "    # Average across all districts in the state\n",
    "    kharif_avg = state_data['Kharif_Rainfall'].mean()\n",
    "    rabi_avg = state_data['Rabi_Rainfall'].mean()\n",
    "    summer_avg = state_data['Summer_Rainfall'].mean()\n",
    "    annual_avg = state_data['Annual_Rainfall'].mean()\n",
    "    \n",
    "    weather_mapping.append({\n",
    "        'State': state,\n",
    "        'Season': 'Kharif',\n",
    "        'Total_Rainfall': kharif_avg,\n",
    "        'Avg_Temperature': 28,\n",
    "        'Avg_Humidity': 78\n",
    "    })\n",
    "    \n",
    "    weather_mapping.append({\n",
    "        'State': state,\n",
    "        'Season': 'Rabi',\n",
    "        'Total_Rainfall': rabi_avg,\n",
    "        'Avg_Temperature': 20,\n",
    "        'Avg_Humidity': 65\n",
    "    })\n",
    "    \n",
    "    weather_mapping.append({\n",
    "        'State': state,\n",
    "        'Season': 'Summer',\n",
    "        'Total_Rainfall': summer_avg,\n",
    "        'Avg_Temperature': 35,\n",
    "        'Avg_Humidity': 60\n",
    "    })\n",
    "    \n",
    "    weather_mapping.append({\n",
    "        'State': state,\n",
    "        'Season': 'Whole Year',\n",
    "        'Total_Rainfall': annual_avg,\n",
    "        'Avg_Temperature': 27,\n",
    "        'Avg_Humidity': 70\n",
    "    })\n",
    "\n",
    "weather_processed = pd.DataFrame(weather_mapping)\n",
    "\n",
    "print(f\"‚úÖ Weather records created: {len(weather_processed)}\")\n",
    "print(f\"   States covered: {weather_processed['State'].nunique()}\")\n",
    "\n",
    "weather_processed.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad6d2b04-a173-4106-931a-2035cb572e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üå™Ô∏è  STEP 4: PROCESSING DISASTER DATA\n",
      "--------------------------------------------------------------------------------\n",
      "‚úÖ Filtered for India: 752 records\n",
      "‚úÖ Disaster records: 563\n",
      "\n",
      "üìä Disaster Types:\n",
      "Disaster_Type\n",
      "Flood         276\n",
      "Cyclone       187\n",
      "Epidemic       58\n",
      "Earthquake     27\n",
      "Drought        15\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üìä Severity Distribution:\n",
      "Severity\n",
      "High      270\n",
      "Medium    243\n",
      "Low        50\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Year</th>\n",
       "      <th>Disaster_Type</th>\n",
       "      <th>Severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bengal</td>\n",
       "      <td>1900</td>\n",
       "      <td>Drought</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Kangra</td>\n",
       "      <td>1905</td>\n",
       "      <td>Earthquake</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Cuddalore</td>\n",
       "      <td>1916</td>\n",
       "      <td>Cyclone</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Punjab Province</td>\n",
       "      <td>1924</td>\n",
       "      <td>Cyclone</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Bezwada</td>\n",
       "      <td>1925</td>\n",
       "      <td>Cyclone</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Bengal</td>\n",
       "      <td>1926</td>\n",
       "      <td>Flood</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Gujarat</td>\n",
       "      <td>1927</td>\n",
       "      <td>Cyclone</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Nellore</td>\n",
       "      <td>1927</td>\n",
       "      <td>Cyclone</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Guntur</td>\n",
       "      <td>1936</td>\n",
       "      <td>Cyclone</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Calcutta</td>\n",
       "      <td>1942</td>\n",
       "      <td>Drought</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               State  Year Disaster_Type Severity\n",
       "1             Bengal  1900       Drought     High\n",
       "9             Kangra  1905    Earthquake     High\n",
       "41         Cuddalore  1916       Cyclone     High\n",
       "72   Punjab Province  1924       Cyclone     High\n",
       "76           Bezwada  1925       Cyclone   Medium\n",
       "85            Bengal  1926         Flood      Low\n",
       "91           Gujarat  1927       Cyclone   Medium\n",
       "92           Nellore  1927       Cyclone     High\n",
       "131           Guntur  1936       Cyclone     High\n",
       "145         Calcutta  1942       Drought     High"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 4: PROCESS DISASTER DATA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüå™Ô∏è  STEP 4: PROCESSING DISASTER DATA\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Filter for India only\n",
    "disaster_df_india = disaster_df[disaster_df['Country'].str.contains('India', case=False, na=False)].copy()\n",
    "print(f\"‚úÖ Filtered for India: {len(disaster_df_india)} records\")\n",
    "\n",
    "# Clean columns\n",
    "disaster_df_india['Year'] = pd.to_numeric(disaster_df_india['Start Year'], errors='coerce')\n",
    "disaster_df_india['Disaster_Type'] = disaster_df_india['Disaster Type'].str.strip().str.title()\n",
    "\n",
    "# Keep only major disaster types\n",
    "major_disasters = ['Flood', 'Drought', 'Storm', 'Earthquake', 'Epidemic']\n",
    "disaster_df_india = disaster_df_india[disaster_df_india['Disaster_Type'].isin(major_disasters)]\n",
    "\n",
    "# Map storms to cyclones\n",
    "disaster_df_india['Disaster_Type'] = disaster_df_india['Disaster_Type'].replace('Storm', 'Cyclone')\n",
    "\n",
    "# Extract state from Location\n",
    "disaster_df_india['State'] = disaster_df_india['Location'].str.extract(r'([A-Za-z\\s]+)', expand=False).str.strip().str.title()\n",
    "\n",
    "# Assign severity based on deaths and affected\n",
    "def assign_severity(row):\n",
    "    deaths = pd.to_numeric(row.get('Total Deaths', 0), errors='coerce')\n",
    "    affected = pd.to_numeric(row.get('Total Affected', 0), errors='coerce')\n",
    "    \n",
    "    if pd.isna(deaths):\n",
    "        deaths = 0\n",
    "    if pd.isna(affected):\n",
    "        affected = 0\n",
    "    \n",
    "    if deaths > 100 or affected > 100000:\n",
    "        return 'High'\n",
    "    elif deaths > 10 or affected > 10000:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'Low'\n",
    "\n",
    "disaster_df_india['Severity'] = disaster_df_india.apply(assign_severity, axis=1)\n",
    "\n",
    "# Keep only necessary columns\n",
    "disaster_processed = disaster_df_india[['State', 'Year', 'Disaster_Type', 'Severity']].dropna(subset=['State', 'Year'])\n",
    "\n",
    "# Standardize state names\n",
    "disaster_processed['State'] = disaster_processed['State'].str.strip().str.title()\n",
    "\n",
    "# Remove duplicates (keep one disaster per state-year-type)\n",
    "disaster_processed = disaster_processed.drop_duplicates(subset=['State', 'Year', 'Disaster_Type'])\n",
    "\n",
    "print(f\"‚úÖ Disaster records: {len(disaster_processed)}\")\n",
    "print(f\"\\nüìä Disaster Types:\")\n",
    "print(disaster_processed['Disaster_Type'].value_counts())\n",
    "print(f\"\\nüìä Severity Distribution:\")\n",
    "print(disaster_processed['Severity'].value_counts())\n",
    "\n",
    "disaster_processed.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07219d37-4ddf-46b6-becf-9a1de9cf2de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üå± STEP 5: GENERATING SOIL DATA\n",
      "--------------------------------------------------------------------------------\n",
      "‚úÖ Soil records created: 30\n",
      "\n",
      "üìä Soil Types:\n",
      "Soil_Type\n",
      "Alluvial    15\n",
      "Red          7\n",
      "Black        3\n",
      "Mountain     3\n",
      "Laterite     2\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>District</th>\n",
       "      <th>Soil_Type</th>\n",
       "      <th>Soil_Quality_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Assam</td>\n",
       "      <td>Assam</td>\n",
       "      <td>Alluvial</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>Red</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kerala</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>Laterite</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>Alluvial</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>West Bengal</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>Alluvial</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Puducherry</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>Alluvial</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Goa</td>\n",
       "      <td>Goa</td>\n",
       "      <td>Laterite</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>Red</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>Red</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Odisha</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>Red</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            State        District Soil_Type  Soil_Quality_Score\n",
       "0           Assam           Assam  Alluvial                0.78\n",
       "1       Karnataka       Karnataka       Red                0.72\n",
       "2          Kerala          Kerala  Laterite                0.61\n",
       "3       Meghalaya       Meghalaya  Alluvial                0.66\n",
       "4     West Bengal     West Bengal  Alluvial                0.76\n",
       "5      Puducherry      Puducherry  Alluvial                0.74\n",
       "6             Goa             Goa  Laterite                0.62\n",
       "7  Andhra Pradesh  Andhra Pradesh       Red                0.64\n",
       "8      Tamil Nadu      Tamil Nadu       Red                0.66\n",
       "9          Odisha          Odisha       Red                0.65"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 5: PROCESS SOIL DATA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüå± STEP 5: GENERATING SOIL DATA\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "state_soil_quality = {\n",
    "    'Punjab': {'type': 'Alluvial', 'quality': 0.88},\n",
    "    'Haryana': {'type': 'Alluvial', 'quality': 0.85},\n",
    "    'Uttar Pradesh': {'type': 'Alluvial', 'quality': 0.82},\n",
    "    'Bihar': {'type': 'Alluvial', 'quality': 0.80},\n",
    "    'West Bengal': {'type': 'Alluvial', 'quality': 0.79},\n",
    "    'Assam': {'type': 'Alluvial', 'quality': 0.75},\n",
    "    'Maharashtra': {'type': 'Black', 'quality': 0.76},\n",
    "    'Madhya Pradesh': {'type': 'Black', 'quality': 0.74},\n",
    "    'Gujarat': {'type': 'Black', 'quality': 0.73},\n",
    "    'Rajasthan': {'type': 'Arid', 'quality': 0.62},\n",
    "    'Karnataka': {'type': 'Red', 'quality': 0.70},\n",
    "    'Tamil Nadu': {'type': 'Red', 'quality': 0.68},\n",
    "    'Andhra Pradesh': {'type': 'Red', 'quality': 0.69},\n",
    "    'Telangana': {'type': 'Red', 'quality': 0.68},\n",
    "    'Kerala': {'type': 'Laterite', 'quality': 0.64},\n",
    "    'Odisha': {'type': 'Red', 'quality': 0.67},\n",
    "    'Chhattisgarh': {'type': 'Red', 'quality': 0.67},\n",
    "    'Jharkhand': {'type': 'Red', 'quality': 0.66},\n",
    "    'Goa': {'type': 'Laterite', 'quality': 0.63},\n",
    "    'Himachal Pradesh': {'type': 'Mountain', 'quality': 0.72},\n",
    "    'Uttarakhand': {'type': 'Mountain', 'quality': 0.71},\n",
    "    'Jammu And Kashmir': {'type': 'Mountain', 'quality': 0.70}\n",
    "}\n",
    "\n",
    "# Create soil records for each state-district combination in crop data\n",
    "soil_records = []\n",
    "state_districts = crop_df[['State', 'District']].drop_duplicates()\n",
    "\n",
    "for _, row in state_districts.iterrows():\n",
    "    state = row['State']\n",
    "    district = row['District']\n",
    "    \n",
    "    soil_info = state_soil_quality.get(state, {'type': 'Alluvial', 'quality': 0.70})\n",
    "    \n",
    "    # Add district-level variation\n",
    "    quality = np.clip(soil_info['quality'] + np.random.uniform(-0.05, 0.05), 0.50, 0.95)\n",
    "    \n",
    "    soil_records.append({\n",
    "        'State': state,\n",
    "        'District': district,\n",
    "        'Soil_Type': soil_info['type'],\n",
    "        'Soil_Quality_Score': round(quality, 2)\n",
    "    })\n",
    "\n",
    "soil_processed = pd.DataFrame(soil_records)\n",
    "\n",
    "print(f\"‚úÖ Soil records created: {len(soil_processed)}\")\n",
    "print(f\"\\nüìä Soil Types:\")\n",
    "print(soil_processed['Soil_Type'].value_counts())\n",
    "\n",
    "soil_processed.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afc0356f-9b05-4206-80f9-eb9f79a6bdb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîó STEP 6: MERGING ALL DATASETS\n",
      "--------------------------------------------------------------------------------\n",
      "Starting with crop data: (19437, 11)\n",
      "‚úÖ After weather merge: (19437, 14)\n",
      "‚úÖ After soil merge: (19437, 16)\n",
      "‚úÖ After disaster merge: (19625, 18)\n",
      "\n",
      "üìä Merged dataset columns:\n",
      "['Crop', 'Year', 'Season', 'State', 'Area', 'Production', 'Annual_Rainfall', 'Fertilizer', 'Pesticide', 'Yield', 'District', 'Total_Rainfall', 'Avg_Temperature', 'Avg_Humidity', 'Soil_Type', 'Soil_Quality_Score', 'Disaster_Type', 'Severity']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crop</th>\n",
       "      <th>Year</th>\n",
       "      <th>Season</th>\n",
       "      <th>State</th>\n",
       "      <th>Area</th>\n",
       "      <th>Production</th>\n",
       "      <th>Annual_Rainfall</th>\n",
       "      <th>Fertilizer</th>\n",
       "      <th>Pesticide</th>\n",
       "      <th>Yield</th>\n",
       "      <th>District</th>\n",
       "      <th>Total_Rainfall</th>\n",
       "      <th>Avg_Temperature</th>\n",
       "      <th>Avg_Humidity</th>\n",
       "      <th>Soil_Type</th>\n",
       "      <th>Soil_Quality_Score</th>\n",
       "      <th>Disaster_Type</th>\n",
       "      <th>Severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arecanut</td>\n",
       "      <td>1997</td>\n",
       "      <td>Whole Year</td>\n",
       "      <td>Assam</td>\n",
       "      <td>73814.0</td>\n",
       "      <td>56708</td>\n",
       "      <td>2051.4</td>\n",
       "      <td>7024878.38</td>\n",
       "      <td>22882.34</td>\n",
       "      <td>0.796087</td>\n",
       "      <td>Assam</td>\n",
       "      <td>2454.359259</td>\n",
       "      <td>27.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Alluvial</td>\n",
       "      <td>0.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arhar/Tur</td>\n",
       "      <td>1997</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>Assam</td>\n",
       "      <td>6637.0</td>\n",
       "      <td>4685</td>\n",
       "      <td>2051.4</td>\n",
       "      <td>631643.29</td>\n",
       "      <td>2057.47</td>\n",
       "      <td>0.710435</td>\n",
       "      <td>Assam</td>\n",
       "      <td>1777.648148</td>\n",
       "      <td>28.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>Alluvial</td>\n",
       "      <td>0.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Castor Seed</td>\n",
       "      <td>1997</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>Assam</td>\n",
       "      <td>796.0</td>\n",
       "      <td>22</td>\n",
       "      <td>2051.4</td>\n",
       "      <td>75755.32</td>\n",
       "      <td>246.76</td>\n",
       "      <td>0.238333</td>\n",
       "      <td>Assam</td>\n",
       "      <td>1777.648148</td>\n",
       "      <td>28.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>Alluvial</td>\n",
       "      <td>0.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coconut</td>\n",
       "      <td>1997</td>\n",
       "      <td>Whole Year</td>\n",
       "      <td>Assam</td>\n",
       "      <td>19656.0</td>\n",
       "      <td>126905000</td>\n",
       "      <td>2051.4</td>\n",
       "      <td>1870661.52</td>\n",
       "      <td>6093.36</td>\n",
       "      <td>5238.051739</td>\n",
       "      <td>Assam</td>\n",
       "      <td>2454.359259</td>\n",
       "      <td>27.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Alluvial</td>\n",
       "      <td>0.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cotton(Lint)</td>\n",
       "      <td>1997</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>Assam</td>\n",
       "      <td>1739.0</td>\n",
       "      <td>794</td>\n",
       "      <td>2051.4</td>\n",
       "      <td>165500.63</td>\n",
       "      <td>539.09</td>\n",
       "      <td>0.420909</td>\n",
       "      <td>Assam</td>\n",
       "      <td>1777.648148</td>\n",
       "      <td>28.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>Alluvial</td>\n",
       "      <td>0.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Crop  Year      Season  State     Area  Production  \\\n",
       "0      Arecanut  1997  Whole Year  Assam  73814.0       56708   \n",
       "1     Arhar/Tur  1997      Kharif  Assam   6637.0        4685   \n",
       "2   Castor Seed  1997      Kharif  Assam    796.0          22   \n",
       "3       Coconut  1997  Whole Year  Assam  19656.0   126905000   \n",
       "4  Cotton(Lint)  1997      Kharif  Assam   1739.0         794   \n",
       "\n",
       "   Annual_Rainfall  Fertilizer  Pesticide        Yield District  \\\n",
       "0           2051.4  7024878.38   22882.34     0.796087    Assam   \n",
       "1           2051.4   631643.29    2057.47     0.710435    Assam   \n",
       "2           2051.4    75755.32     246.76     0.238333    Assam   \n",
       "3           2051.4  1870661.52    6093.36  5238.051739    Assam   \n",
       "4           2051.4   165500.63     539.09     0.420909    Assam   \n",
       "\n",
       "   Total_Rainfall  Avg_Temperature  Avg_Humidity Soil_Type  \\\n",
       "0     2454.359259             27.0          70.0  Alluvial   \n",
       "1     1777.648148             28.0          78.0  Alluvial   \n",
       "2     1777.648148             28.0          78.0  Alluvial   \n",
       "3     2454.359259             27.0          70.0  Alluvial   \n",
       "4     1777.648148             28.0          78.0  Alluvial   \n",
       "\n",
       "   Soil_Quality_Score Disaster_Type Severity  \n",
       "0                0.78           NaN      NaN  \n",
       "1                0.78           NaN      NaN  \n",
       "2                0.78           NaN      NaN  \n",
       "3                0.78           NaN      NaN  \n",
       "4                0.78           NaN      NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 6: MERGE ALL DATASETS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüîó STEP 6: MERGING ALL DATASETS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "print(f\"Starting with crop data: {crop_df.shape}\")\n",
    "\n",
    "# Merge with weather (by State and Season only, since weather doesn't have years)\n",
    "merged = pd.merge(\n",
    "    crop_df,\n",
    "    weather_processed,\n",
    "    on=['State', 'Season'],\n",
    "    how='left'\n",
    ")\n",
    "print(f\"‚úÖ After weather merge: {merged.shape}\")\n",
    "\n",
    "# Merge with soil (by State and District)\n",
    "merged = pd.merge(\n",
    "    merged,\n",
    "    soil_processed,\n",
    "    on=['State', 'District'],\n",
    "    how='left'\n",
    ")\n",
    "print(f\"‚úÖ After soil merge: {merged.shape}\")\n",
    "\n",
    "# Merge with disasters (by State and Year)\n",
    "merged = pd.merge(\n",
    "    merged,\n",
    "    disaster_processed[['State', 'Year', 'Disaster_Type', 'Severity']],\n",
    "    on=['State', 'Year'],\n",
    "    how='left'\n",
    ")\n",
    "print(f\"‚úÖ After disaster merge: {merged.shape}\")\n",
    "\n",
    "print(f\"\\nüìä Merged dataset columns:\")\n",
    "print(merged.columns.tolist())\n",
    "\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e5f5fdf-380a-4e41-aa7c-3776c457fd92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚öôÔ∏è  STEP 7: FEATURE ENGINEERING\n",
      "--------------------------------------------------------------------------------\n",
      "‚úÖ Features created:\n",
      "   - Rainfall_Deviation\n",
      "   - Temperature_Deviation\n",
      "   - Disaster_Occurred\n",
      "   - Severity_Score\n",
      "   - Season_Encoded\n",
      "\n",
      "üìä Missing values:\n",
      "Total_Rainfall                4512\n",
      "Avg_Temperature               4512\n",
      "Avg_Humidity                  4512\n",
      "Disaster_Type                16995\n",
      "Severity                     16995\n",
      "State_Season_Avg_Rainfall     4512\n",
      "Rainfall_Deviation            4512\n",
      "State_Season_Avg_Temp         4512\n",
      "Temperature_Deviation         4512\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crop</th>\n",
       "      <th>Year</th>\n",
       "      <th>Season</th>\n",
       "      <th>State</th>\n",
       "      <th>Area</th>\n",
       "      <th>Production</th>\n",
       "      <th>Annual_Rainfall</th>\n",
       "      <th>Fertilizer</th>\n",
       "      <th>Pesticide</th>\n",
       "      <th>Yield</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Quality_Score</th>\n",
       "      <th>Disaster_Type</th>\n",
       "      <th>Severity</th>\n",
       "      <th>State_Season_Avg_Rainfall</th>\n",
       "      <th>Rainfall_Deviation</th>\n",
       "      <th>State_Season_Avg_Temp</th>\n",
       "      <th>Temperature_Deviation</th>\n",
       "      <th>Disaster_Occurred</th>\n",
       "      <th>Severity_Score</th>\n",
       "      <th>Season_Encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arecanut</td>\n",
       "      <td>1997</td>\n",
       "      <td>Whole Year</td>\n",
       "      <td>Assam</td>\n",
       "      <td>73814.0</td>\n",
       "      <td>56708</td>\n",
       "      <td>2051.4</td>\n",
       "      <td>7024878.38</td>\n",
       "      <td>22882.34</td>\n",
       "      <td>0.796087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2454.359259</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arhar/Tur</td>\n",
       "      <td>1997</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>Assam</td>\n",
       "      <td>6637.0</td>\n",
       "      <td>4685</td>\n",
       "      <td>2051.4</td>\n",
       "      <td>631643.29</td>\n",
       "      <td>2057.47</td>\n",
       "      <td>0.710435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1777.648148</td>\n",
       "      <td>-1.278351e-14</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Castor Seed</td>\n",
       "      <td>1997</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>Assam</td>\n",
       "      <td>796.0</td>\n",
       "      <td>22</td>\n",
       "      <td>2051.4</td>\n",
       "      <td>75755.32</td>\n",
       "      <td>246.76</td>\n",
       "      <td>0.238333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1777.648148</td>\n",
       "      <td>-1.278351e-14</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coconut</td>\n",
       "      <td>1997</td>\n",
       "      <td>Whole Year</td>\n",
       "      <td>Assam</td>\n",
       "      <td>19656.0</td>\n",
       "      <td>126905000</td>\n",
       "      <td>2051.4</td>\n",
       "      <td>1870661.52</td>\n",
       "      <td>6093.36</td>\n",
       "      <td>5238.051739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2454.359259</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cotton(Lint)</td>\n",
       "      <td>1997</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>Assam</td>\n",
       "      <td>1739.0</td>\n",
       "      <td>794</td>\n",
       "      <td>2051.4</td>\n",
       "      <td>165500.63</td>\n",
       "      <td>539.09</td>\n",
       "      <td>0.420909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1777.648148</td>\n",
       "      <td>-1.278351e-14</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Crop  Year      Season  State     Area  Production  \\\n",
       "0      Arecanut  1997  Whole Year  Assam  73814.0       56708   \n",
       "1     Arhar/Tur  1997      Kharif  Assam   6637.0        4685   \n",
       "2   Castor Seed  1997      Kharif  Assam    796.0          22   \n",
       "3       Coconut  1997  Whole Year  Assam  19656.0   126905000   \n",
       "4  Cotton(Lint)  1997      Kharif  Assam   1739.0         794   \n",
       "\n",
       "   Annual_Rainfall  Fertilizer  Pesticide        Yield  ...  \\\n",
       "0           2051.4  7024878.38   22882.34     0.796087  ...   \n",
       "1           2051.4   631643.29    2057.47     0.710435  ...   \n",
       "2           2051.4    75755.32     246.76     0.238333  ...   \n",
       "3           2051.4  1870661.52    6093.36  5238.051739  ...   \n",
       "4           2051.4   165500.63     539.09     0.420909  ...   \n",
       "\n",
       "  Soil_Quality_Score  Disaster_Type  Severity  State_Season_Avg_Rainfall  \\\n",
       "0               0.78            NaN       NaN                2454.359259   \n",
       "1               0.78            NaN       NaN                1777.648148   \n",
       "2               0.78            NaN       NaN                1777.648148   \n",
       "3               0.78            NaN       NaN                2454.359259   \n",
       "4               0.78            NaN       NaN                1777.648148   \n",
       "\n",
       "  Rainfall_Deviation  State_Season_Avg_Temp Temperature_Deviation  \\\n",
       "0       0.000000e+00                   27.0                   0.0   \n",
       "1      -1.278351e-14                   28.0                   0.0   \n",
       "2      -1.278351e-14                   28.0                   0.0   \n",
       "3       0.000000e+00                   27.0                   0.0   \n",
       "4      -1.278351e-14                   28.0                   0.0   \n",
       "\n",
       "  Disaster_Occurred  Severity_Score  Season_Encoded  \n",
       "0                 0             0.0               4  \n",
       "1                 0             0.0               1  \n",
       "2                 0             0.0               1  \n",
       "3                 0             0.0               4  \n",
       "4                 0             0.0               1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 7: FEATURE ENGINEERING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n‚öôÔ∏è  STEP 7: FEATURE ENGINEERING\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Fill missing weather values with state-season averages\n",
    "for col in ['Total_Rainfall', 'Avg_Temperature', 'Avg_Humidity']:\n",
    "    if col in merged.columns:\n",
    "        merged[col] = merged.groupby(['State', 'Season'])[col].transform(\n",
    "            lambda x: x.fillna(x.mean())\n",
    "        )\n",
    "\n",
    "# Fill remaining NaN in Soil_Quality_Score with state average\n",
    "merged['Soil_Quality_Score'] = merged.groupby('State')['Soil_Quality_Score'].transform(\n",
    "    lambda x: x.fillna(x.mean())\n",
    ")\n",
    "\n",
    "# 1. Rainfall deviation from state-season average\n",
    "merged['State_Season_Avg_Rainfall'] = merged.groupby(['State', 'Season'])['Total_Rainfall'].transform('mean')\n",
    "merged['Rainfall_Deviation'] = ((merged['Total_Rainfall'] - merged['State_Season_Avg_Rainfall']) / \n",
    "                                 (merged['State_Season_Avg_Rainfall'] + 1)) * 100\n",
    "\n",
    "# 2. Temperature deviation\n",
    "merged['State_Season_Avg_Temp'] = merged.groupby(['State', 'Season'])['Avg_Temperature'].transform('mean')\n",
    "merged['Temperature_Deviation'] = ((merged['Avg_Temperature'] - merged['State_Season_Avg_Temp']) / \n",
    "                                    (merged['State_Season_Avg_Temp'] + 1)) * 100\n",
    "\n",
    "# 3. Disaster flags\n",
    "merged['Disaster_Occurred'] = merged['Disaster_Type'].notna().astype(int)\n",
    "\n",
    "severity_map = {'Low': 1, 'Medium': 2, 'High': 3}\n",
    "merged['Severity_Score'] = merged['Severity'].map(severity_map).fillna(0)\n",
    "\n",
    "# 4. Season encoding\n",
    "season_map = {\n",
    "    'Kharif': 1, 'Rabi': 2, 'Summer': 3, 'Zaid': 3,\n",
    "    'Whole Year': 4, 'Autumn': 5, 'Winter': 6\n",
    "}\n",
    "merged['Season_Encoded'] = merged['Season'].map(season_map).fillna(4)\n",
    "\n",
    "print(\"‚úÖ Features created:\")\n",
    "print(\"   - Rainfall_Deviation\")\n",
    "print(\"   - Temperature_Deviation\")\n",
    "print(\"   - Disaster_Occurred\")\n",
    "print(\"   - Severity_Score\")\n",
    "print(\"   - Season_Encoded\")\n",
    "\n",
    "# Check for any remaining NaN values\n",
    "print(f\"\\nüìä Missing values:\")\n",
    "print(merged.isnull().sum()[merged.isnull().sum() > 0])\n",
    "\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54263347-32c4-4162-b76f-68c8bf3d5ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ STEP 8: CREATING TARGET VARIABLE\n",
      "--------------------------------------------------------------------------------\n",
      "‚úÖ Target created:\n",
      "   Failures: 4,870 (24.82%)\n",
      "   Success: 14,755 (75.18%)\n",
      "\n",
      "üìä Failure distribution by crop (top 10):\n",
      "                   sum  count  failure_rate\n",
      "Crop                                       \n",
      "Rice               300   1203     24.937656\n",
      "Maize              244    980     24.897959\n",
      "Moong(Green Gram)  184    738     24.932249\n",
      "Urad               183    733     24.965894\n",
      "Groundnut          181    726     24.931129\n",
      "Sesamum            171    686     24.927114\n",
      "Potato             155    626     24.760383\n",
      "Sugarcane          151    606     24.917492\n",
      "Wheat              136    545     24.954128\n",
      "Rapeseed &Mustard  132    529     24.952741\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crop</th>\n",
       "      <th>State</th>\n",
       "      <th>Year</th>\n",
       "      <th>Season</th>\n",
       "      <th>Yield</th>\n",
       "      <th>Crop_Failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arecanut</td>\n",
       "      <td>Assam</td>\n",
       "      <td>1997</td>\n",
       "      <td>Whole Year</td>\n",
       "      <td>0.796087</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arhar/Tur</td>\n",
       "      <td>Assam</td>\n",
       "      <td>1997</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>0.710435</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Castor Seed</td>\n",
       "      <td>Assam</td>\n",
       "      <td>1997</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>0.238333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coconut</td>\n",
       "      <td>Assam</td>\n",
       "      <td>1997</td>\n",
       "      <td>Whole Year</td>\n",
       "      <td>5238.051739</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cotton(Lint)</td>\n",
       "      <td>Assam</td>\n",
       "      <td>1997</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>0.420909</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dry Chillies</td>\n",
       "      <td>Assam</td>\n",
       "      <td>1997</td>\n",
       "      <td>Whole Year</td>\n",
       "      <td>0.643636</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gram</td>\n",
       "      <td>Assam</td>\n",
       "      <td>1997</td>\n",
       "      <td>Rabi</td>\n",
       "      <td>0.465455</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jute</td>\n",
       "      <td>Assam</td>\n",
       "      <td>1997</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>9.919565</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Linseed</td>\n",
       "      <td>Assam</td>\n",
       "      <td>1997</td>\n",
       "      <td>Rabi</td>\n",
       "      <td>0.461364</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Maize</td>\n",
       "      <td>Assam</td>\n",
       "      <td>1997</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>0.615652</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Crop  State  Year      Season        Yield  Crop_Failure\n",
       "0      Arecanut  Assam  1997  Whole Year     0.796087             1\n",
       "1     Arhar/Tur  Assam  1997      Kharif     0.710435             0\n",
       "2   Castor Seed  Assam  1997      Kharif     0.238333             1\n",
       "3       Coconut  Assam  1997  Whole Year  5238.051739             1\n",
       "4  Cotton(Lint)  Assam  1997      Kharif     0.420909             1\n",
       "5  Dry Chillies  Assam  1997  Whole Year     0.643636             1\n",
       "6          Gram  Assam  1997        Rabi     0.465455             1\n",
       "7          Jute  Assam  1997      Kharif     9.919565             0\n",
       "8       Linseed  Assam  1997        Rabi     0.461364             0\n",
       "9         Maize  Assam  1997      Kharif     0.615652             1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 8: CREATE TARGET VARIABLE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüéØ STEP 8: CREATING TARGET VARIABLE\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Calculate yield percentile by crop\n",
    "merged['Yield_Percentile'] = merged.groupby('Crop')['Yield'].transform(\n",
    "    lambda x: x.rank(pct=True)\n",
    ")\n",
    "\n",
    "# Bottom 25% = failure\n",
    "merged['Crop_Failure'] = (merged['Yield_Percentile'] < 0.25).astype(int)\n",
    "\n",
    "failure_count = merged['Crop_Failure'].sum()\n",
    "success_count = (merged['Crop_Failure'] == 0).sum()\n",
    "failure_rate = (failure_count / len(merged)) * 100\n",
    "\n",
    "print(f\"‚úÖ Target created:\")\n",
    "print(f\"   Failures: {failure_count:,} ({failure_rate:.2f}%)\")\n",
    "print(f\"   Success: {success_count:,} ({100-failure_rate:.2f}%)\")\n",
    "\n",
    "print(f\"\\nüìä Failure distribution by crop (top 10):\")\n",
    "failure_by_crop = merged.groupby('Crop')['Crop_Failure'].agg(['sum', 'count', 'mean'])\n",
    "failure_by_crop['failure_rate'] = failure_by_crop['mean'] * 100\n",
    "failure_by_crop = failure_by_crop.sort_values('sum', ascending=False).head(10)\n",
    "print(failure_by_crop[['sum', 'count', 'failure_rate']])\n",
    "\n",
    "merged[['Crop', 'State', 'Year', 'Season', 'Yield', 'Crop_Failure']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb111249-9510-4296-ba49-8e43bbfc081a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üßπ STEP 9: FINAL CLEANUP\n",
      "--------------------------------------------------------------------------------\n",
      "Shape before cleanup: (19625, 27)\n",
      "Shape after cleanup: (15113, 27)\n",
      "Shape after removing duplicates: (15113, 27)\n",
      "\n",
      "‚úÖ Final dataset ready!\n",
      "   Total records: 15,113\n",
      "   Years: 1997 - 2019\n",
      "   States: 24\n",
      "   Crops: 55\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 15113 entries, 0 to 19624\n",
      "Data columns (total 27 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Crop                       15113 non-null  object \n",
      " 1   Year                       15113 non-null  int64  \n",
      " 2   Season                     15113 non-null  object \n",
      " 3   State                      15113 non-null  object \n",
      " 4   Area                       15113 non-null  float64\n",
      " 5   Production                 15113 non-null  int64  \n",
      " 6   Annual_Rainfall            15113 non-null  float64\n",
      " 7   Fertilizer                 15113 non-null  float64\n",
      " 8   Pesticide                  15113 non-null  float64\n",
      " 9   Yield                      15113 non-null  float64\n",
      " 10  District                   15113 non-null  object \n",
      " 11  Total_Rainfall             15113 non-null  float64\n",
      " 12  Avg_Temperature            15113 non-null  float64\n",
      " 13  Avg_Humidity               15113 non-null  float64\n",
      " 14  Soil_Type                  15113 non-null  object \n",
      " 15  Soil_Quality_Score         15113 non-null  float64\n",
      " 16  Disaster_Type              2372 non-null   object \n",
      " 17  Severity                   2372 non-null   object \n",
      " 18  State_Season_Avg_Rainfall  15113 non-null  float64\n",
      " 19  Rainfall_Deviation         15113 non-null  float64\n",
      " 20  State_Season_Avg_Temp      15113 non-null  float64\n",
      " 21  Temperature_Deviation      15113 non-null  float64\n",
      " 22  Disaster_Occurred          15113 non-null  int32  \n",
      " 23  Severity_Score             15113 non-null  float64\n",
      " 24  Season_Encoded             15113 non-null  int64  \n",
      " 25  Yield_Percentile           15113 non-null  float64\n",
      " 26  Crop_Failure               15113 non-null  int32  \n",
      "dtypes: float64(15), int32(2), int64(3), object(7)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 9: FINAL CLEANUP\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüßπ STEP 9: FINAL CLEANUP\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Remove rows with critical missing values\n",
    "critical_cols = [\n",
    "    'State', 'District', 'Crop', 'Year', 'Season', 'Yield',\n",
    "    'Total_Rainfall', 'Avg_Temperature', 'Avg_Humidity',\n",
    "    'Soil_Quality_Score', 'Crop_Failure'\n",
    "]\n",
    "\n",
    "print(f\"Shape before cleanup: {merged.shape}\")\n",
    "merged_clean = merged.dropna(subset=critical_cols)\n",
    "print(f\"Shape after cleanup: {merged_clean.shape}\")\n",
    "\n",
    "# Remove any duplicate rows\n",
    "merged_clean = merged_clean.drop_duplicates()\n",
    "print(f\"Shape after removing duplicates: {merged_clean.shape}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Final dataset ready!\")\n",
    "print(f\"   Total records: {len(merged_clean):,}\")\n",
    "print(f\"   Years: {int(merged_clean['Year'].min())} - {int(merged_clean['Year'].max())}\")\n",
    "print(f\"   States: {merged_clean['State'].nunique()}\")\n",
    "print(f\"   Crops: {merged_clean['Crop'].nunique()}\")\n",
    "\n",
    "merged_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a938317-2114-49ab-804a-123d6fc8e3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ STEP 10: SAVING PROCESSED DATA\n",
      "--------------------------------------------------------------------------------\n",
      "‚úÖ Saved merged dataset: ../data/processed/merged_dataset.csv\n",
      "‚úÖ Saved district info: ../models/district_info.pkl\n",
      "\n",
      "================================================================================\n",
      "                              ‚úÖ PREPROCESSING COMPLETE!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 10: SAVE PROCESSED DATA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüíæ STEP 10: SAVING PROCESSED DATA\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "\n",
    "# Save main dataset\n",
    "output_path = '../data/processed/merged_dataset.csv'\n",
    "merged_clean.to_csv(output_path, index=False)\n",
    "print(f\"‚úÖ Saved merged dataset: {output_path}\")\n",
    "\n",
    "# Save district information for predictions\n",
    "district_info = {}\n",
    "for _, row in merged_clean[['State', 'District', 'Soil_Type', 'Soil_Quality_Score']].drop_duplicates().iterrows():\n",
    "    key = f\"{row['District']}, {row['State']}\"\n",
    "    district_info[key] = {\n",
    "        'soil_type': row['Soil_Type'],\n",
    "        'soil_quality': row['Soil_Quality_Score'],\n",
    "        'state': row['State']\n",
    "    }\n",
    "\n",
    "# Create models directory\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "# Save district info\n",
    "with open('../models/district_info.pkl', 'wb') as f:\n",
    "    pickle.dump(district_info, f)\n",
    "print(f\"‚úÖ Saved district info: ../models/district_info.pkl\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" \"*30 + \"‚úÖ PREPROCESSING COMPLETE!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c2ae4c3-ae8e-4db2-b8f5-b52773847b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä FINAL DATASET SUMMARY\n",
      "================================================================================\n",
      "\n",
      "üåæ TOP 10 CROPS BY RECORDS:\n",
      "Crop\n",
      "Maize                776\n",
      "Rice                 722\n",
      "Moong(Green Gram)    535\n",
      "Groundnut            534\n",
      "Urad                 508\n",
      "Sugarcane            495\n",
      "Sesamum              477\n",
      "Potato               459\n",
      "Wheat                450\n",
      "Jowar                447\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üèõÔ∏è  TOP 10 STATES BY RECORDS:\n",
      "State\n",
      "Karnataka         1426\n",
      "Andhra Pradesh    1333\n",
      "West Bengal        955\n",
      "Uttar Pradesh      866\n",
      "Bihar              861\n",
      "Madhya Pradesh     839\n",
      "Gujarat            813\n",
      "Tamil Nadu         790\n",
      "Maharashtra        766\n",
      "Assam              711\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üìÖ RECORDS BY YEAR:\n",
      "Year\n",
      "2010    655\n",
      "2011    693\n",
      "2012    676\n",
      "2013    693\n",
      "2014    686\n",
      "2015    734\n",
      "2016    767\n",
      "2017    794\n",
      "2018    825\n",
      "2019    767\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üéØ CROP FAILURE STATISTICS:\n",
      "   Total Records: 15,113\n",
      "   Failure Cases: 3,310\n",
      "   Success Cases: 11,803\n",
      "   Failure Rate: 21.90%\n",
      "\n",
      "‚úÖ READY FOR MODEL TRAINING!\n",
      "   Next step: Run train_model.ipynb\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crop</th>\n",
       "      <th>State</th>\n",
       "      <th>Year</th>\n",
       "      <th>Season</th>\n",
       "      <th>Yield</th>\n",
       "      <th>Crop_Failure</th>\n",
       "      <th>Total_Rainfall</th>\n",
       "      <th>Avg_Temperature</th>\n",
       "      <th>Disaster_Occurred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arecanut</td>\n",
       "      <td>Assam</td>\n",
       "      <td>1997</td>\n",
       "      <td>Whole Year</td>\n",
       "      <td>0.796087</td>\n",
       "      <td>1</td>\n",
       "      <td>2454.359259</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arhar/Tur</td>\n",
       "      <td>Assam</td>\n",
       "      <td>1997</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>0.710435</td>\n",
       "      <td>0</td>\n",
       "      <td>1777.648148</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Castor Seed</td>\n",
       "      <td>Assam</td>\n",
       "      <td>1997</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>0.238333</td>\n",
       "      <td>1</td>\n",
       "      <td>1777.648148</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coconut</td>\n",
       "      <td>Assam</td>\n",
       "      <td>1997</td>\n",
       "      <td>Whole Year</td>\n",
       "      <td>5238.051739</td>\n",
       "      <td>1</td>\n",
       "      <td>2454.359259</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cotton(Lint)</td>\n",
       "      <td>Assam</td>\n",
       "      <td>1997</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>0.420909</td>\n",
       "      <td>1</td>\n",
       "      <td>1777.648148</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dry Chillies</td>\n",
       "      <td>Assam</td>\n",
       "      <td>1997</td>\n",
       "      <td>Whole Year</td>\n",
       "      <td>0.643636</td>\n",
       "      <td>1</td>\n",
       "      <td>2454.359259</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gram</td>\n",
       "      <td>Assam</td>\n",
       "      <td>1997</td>\n",
       "      <td>Rabi</td>\n",
       "      <td>0.465455</td>\n",
       "      <td>1</td>\n",
       "      <td>161.574074</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jute</td>\n",
       "      <td>Assam</td>\n",
       "      <td>1997</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>9.919565</td>\n",
       "      <td>0</td>\n",
       "      <td>1777.648148</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Linseed</td>\n",
       "      <td>Assam</td>\n",
       "      <td>1997</td>\n",
       "      <td>Rabi</td>\n",
       "      <td>0.461364</td>\n",
       "      <td>0</td>\n",
       "      <td>161.574074</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Maize</td>\n",
       "      <td>Assam</td>\n",
       "      <td>1997</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>0.615652</td>\n",
       "      <td>1</td>\n",
       "      <td>1777.648148</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mesta</td>\n",
       "      <td>Assam</td>\n",
       "      <td>1997</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>4.568947</td>\n",
       "      <td>0</td>\n",
       "      <td>1777.648148</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Niger Seed</td>\n",
       "      <td>Assam</td>\n",
       "      <td>1997</td>\n",
       "      <td>Whole Year</td>\n",
       "      <td>0.482353</td>\n",
       "      <td>0</td>\n",
       "      <td>2454.359259</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Onion</td>\n",
       "      <td>Assam</td>\n",
       "      <td>1997</td>\n",
       "      <td>Whole Year</td>\n",
       "      <td>2.342609</td>\n",
       "      <td>1</td>\n",
       "      <td>2454.359259</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Other  Rabi Pulses</td>\n",
       "      <td>Assam</td>\n",
       "      <td>1997</td>\n",
       "      <td>Rabi</td>\n",
       "      <td>0.520870</td>\n",
       "      <td>0</td>\n",
       "      <td>161.574074</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Potato</td>\n",
       "      <td>Assam</td>\n",
       "      <td>1997</td>\n",
       "      <td>Whole Year</td>\n",
       "      <td>7.561304</td>\n",
       "      <td>0</td>\n",
       "      <td>2454.359259</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Rapeseed &amp;Mustard</td>\n",
       "      <td>Assam</td>\n",
       "      <td>1997</td>\n",
       "      <td>Rabi</td>\n",
       "      <td>0.554783</td>\n",
       "      <td>0</td>\n",
       "      <td>161.574074</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Rice</td>\n",
       "      <td>Assam</td>\n",
       "      <td>1997</td>\n",
       "      <td>Summer</td>\n",
       "      <td>1.060435</td>\n",
       "      <td>1</td>\n",
       "      <td>980.322222</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sesamum</td>\n",
       "      <td>Assam</td>\n",
       "      <td>1997</td>\n",
       "      <td>Whole Year</td>\n",
       "      <td>0.487391</td>\n",
       "      <td>0</td>\n",
       "      <td>2454.359259</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Small Millets</td>\n",
       "      <td>Assam</td>\n",
       "      <td>1997</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>0.473000</td>\n",
       "      <td>1</td>\n",
       "      <td>1777.648148</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Sugarcane</td>\n",
       "      <td>Assam</td>\n",
       "      <td>1997</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>41.896957</td>\n",
       "      <td>0</td>\n",
       "      <td>1777.648148</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Crop  State  Year      Season        Yield  Crop_Failure  \\\n",
       "0             Arecanut  Assam  1997  Whole Year     0.796087             1   \n",
       "1            Arhar/Tur  Assam  1997      Kharif     0.710435             0   \n",
       "2          Castor Seed  Assam  1997      Kharif     0.238333             1   \n",
       "3              Coconut  Assam  1997  Whole Year  5238.051739             1   \n",
       "4         Cotton(Lint)  Assam  1997      Kharif     0.420909             1   \n",
       "5         Dry Chillies  Assam  1997  Whole Year     0.643636             1   \n",
       "6                 Gram  Assam  1997        Rabi     0.465455             1   \n",
       "7                 Jute  Assam  1997      Kharif     9.919565             0   \n",
       "8              Linseed  Assam  1997        Rabi     0.461364             0   \n",
       "9                Maize  Assam  1997      Kharif     0.615652             1   \n",
       "10               Mesta  Assam  1997      Kharif     4.568947             0   \n",
       "11          Niger Seed  Assam  1997  Whole Year     0.482353             0   \n",
       "12               Onion  Assam  1997  Whole Year     2.342609             1   \n",
       "13  Other  Rabi Pulses  Assam  1997        Rabi     0.520870             0   \n",
       "14              Potato  Assam  1997  Whole Year     7.561304             0   \n",
       "15   Rapeseed &Mustard  Assam  1997        Rabi     0.554783             0   \n",
       "17                Rice  Assam  1997      Summer     1.060435             1   \n",
       "19             Sesamum  Assam  1997  Whole Year     0.487391             0   \n",
       "20       Small Millets  Assam  1997      Kharif     0.473000             1   \n",
       "21           Sugarcane  Assam  1997      Kharif    41.896957             0   \n",
       "\n",
       "    Total_Rainfall  Avg_Temperature  Disaster_Occurred  \n",
       "0      2454.359259             27.0                  0  \n",
       "1      1777.648148             28.0                  0  \n",
       "2      1777.648148             28.0                  0  \n",
       "3      2454.359259             27.0                  0  \n",
       "4      1777.648148             28.0                  0  \n",
       "5      2454.359259             27.0                  0  \n",
       "6       161.574074             20.0                  0  \n",
       "7      1777.648148             28.0                  0  \n",
       "8       161.574074             20.0                  0  \n",
       "9      1777.648148             28.0                  0  \n",
       "10     1777.648148             28.0                  0  \n",
       "11     2454.359259             27.0                  0  \n",
       "12     2454.359259             27.0                  0  \n",
       "13      161.574074             20.0                  0  \n",
       "14     2454.359259             27.0                  0  \n",
       "15      161.574074             20.0                  0  \n",
       "17      980.322222             35.0                  0  \n",
       "19     2454.359259             27.0                  0  \n",
       "20     1777.648148             28.0                  0  \n",
       "21     1777.648148             28.0                  0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 11: FINAL SUMMARY & VISUALIZATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nüìä FINAL DATASET SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüåæ TOP 10 CROPS BY RECORDS:\")\n",
    "print(merged_clean['Crop'].value_counts().head(10))\n",
    "\n",
    "print(f\"\\nüèõÔ∏è  TOP 10 STATES BY RECORDS:\")\n",
    "print(merged_clean['State'].value_counts().head(10))\n",
    "\n",
    "print(f\"\\nüìÖ RECORDS BY YEAR:\")\n",
    "print(merged_clean['Year'].value_counts().sort_index().tail(10))\n",
    "\n",
    "print(f\"\\nüéØ CROP FAILURE STATISTICS:\")\n",
    "print(f\"   Total Records: {len(merged_clean):,}\")\n",
    "print(f\"   Failure Cases: {merged_clean['Crop_Failure'].sum():,}\")\n",
    "print(f\"   Success Cases: {(merged_clean['Crop_Failure'] == 0).sum():,}\")\n",
    "print(f\"   Failure Rate: {merged_clean['Crop_Failure'].mean()*100:.2f}%\")\n",
    "\n",
    "print(\"\\n‚úÖ READY FOR MODEL TRAINING!\")\n",
    "print(\"   Next step: Run train_model.ipynb\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Display final sample\n",
    "merged_clean[['Crop', 'State', 'Year', 'Season', 'Yield', 'Crop_Failure', \n",
    "              'Total_Rainfall', 'Avg_Temperature', 'Disaster_Occurred']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7185ed6-7205-4b1a-90cd-946ac7926795",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
